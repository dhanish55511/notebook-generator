<div class="sect2"><a id="GUID-B2AF509E-03AD-40BE-A7CF-A2109FAC5DE5" name="GUID-B2AF509E-03AD-40BE-A7CF-A2109FAC5DE5"></a><h3 class="sect3" id="MLSQL-GUID-B2AF509E-03AD-40BE-A7CF-A2109FAC5DE5">Build Model</h3>
<div>
<p>Build your model using the training data set. Use the <code class="codeph">DBMS_DATA_MINING.CREATE_MODEL2</code> procedure to build your model and specify the model settings. 
                  </p>
<div class="section">
<p>For a supervised learning, like Classification, before creating the model, split the data into training and test data. Although you can use the entire data set to build a model, it is difficult to validate the model unless there are new data sets available. Therefore, to evaluate the model and to accurately assess the performance of the model on the same data, you generally split or separate the data into training and test data. You use the training data set to train the model and then use the test data set to test the accuracy of the model by running prediction queries. The testing data set already contains known values for the attribute that you want to predict. It is thus easy to determine whether the predictions of the model are correct. </p>
</div>
<div class="section">
<p class="subhead2" id="GUID-B2AF509E-03AD-40BE-A7CF-A2109FAC5DE5__GUID-A680E01E-E8AE-4701-A513-1EB6CD132993">Algorithm Selection</p>
<p>Before you build a model, choose the suitable algorithm. You can choose one of the following algorithms to solve a classification problem:</p>
<ul id="GUID-B2AF509E-03AD-40BE-A7CF-A2109FAC5DE5__UL_XPK_VCD_H4B" style="list-style-type: disc;">
<li>Decision Tree</li>
<li>Explicit Semantic Analysis (ESM)</li>
<li>Generalized Linear Model (GLM)</li>
<li>Naive Bayes</li>
<li>Random Forest</li>
<li>Support Vector Machine (SVM)</li>
<li>XGBoost</li>
</ul>
<p>From the above algorithms, ESM is more about Natural Language Processing (NLP) and text mining. ESM does not apply to this use case and data. If you were to select a relatively simple linear model like GLM, the prediction accuracy can be further improved by the Random Forest algorithm. Random Forest is an ensemble method that builds multiple decision trees on subsets of the data re-sampled at each time (bagging). This avoids the overfitting for a single decision tree. The random forest model is a widely used ensemble method that is known to have higher accuracy than linear models. Thus, Random Forest is selected for this use case.</p>
<p>For this use case, split the data into 60/40 as training and test data. You build the model using the training data and once the model is built, score the test data using the model. </p>
<p>The following steps guide you to split your data and build your model with the selected algorithm.</p>
</div>
<ol>
<li class="stepexpand"><span>To create the training and test data with 60/40 split, run the following statement:</span><div><pre class="oac_no_warn" dir="ltr">CREATE OR REPLACE VIEW TRAINING_DATA AS SELECT * FROM CUSTOMERDATA SAMPLE (60) SEED (1);
--DBMS_OUTPUT.PUT_LINE ('Created TRAINING_DATA');
CREATE OR REPLACE VIEW TEST_DATA AS SELECT * FROM CUSTOMERDATA MINUS SELECT * FROM TRAINING_DATA;
--DBMS_OUTPUT.PUT_LINE ('Created TEST_DATA');
 </pre></div>
<div><pre class="nocopybutton"><code>
View TRAINING_DATA created.
---------------------------
View TEST_DATA created.</code></pre></div>
</li>
<li class="stepexpand"><span>To view the data in the <code class="codeph">training_data</code> view, run the following statement:</span><div class="tabbed-interface" data-example-id="togglable-tabs">
<ul class="nav nav-tabs" id="myTabs01_d30750e619" role="tablist"></ul>
<div class="tab-content" id="tabbedContent"></div>
</div>
<div><pre class="pre codeblock"><code>SELECT * FROM TRAINING_DATA;</code></pre></div>
<div><img alt="training_data view" height="439" id="GUID-B2AF509E-03AD-40BE-A7CF-A2109FAC5DE5__IMAGE_Y5Q_QPB_Q4B" src="img/classification_training_data.png" title="training_data view" width="1788"/></div>
</li>
<li class="stepexpand"><span>To view the data in the <code class="codeph">test_data</code> view, run the following statement:</span><div><pre class="pre codeblock"><code>SELECT* FROM TEST_DATA;</code></pre></div>
<div><img alt="TEST_DATA view" height="441" id="GUID-B2AF509E-03AD-40BE-A7CF-A2109FAC5DE5__IMAGE_PVQ_TPB_Q4B" src="img/classification_test_data.png" title="TEST_DATA view" width="1788"/></div>
</li>
<li class="stepexpand"><span>To view the distribution of <code class="codeph">HOME_THEATER_PACKAGE</code> (target) owners, run the following script:</span><div><pre class="pre codeblock"><code>%script
select HOME_THEATER_PACKAGE, count(1)
from training_data
group by HOME_THEATER_PACKAGE;</code></pre></div>
<div><pre class="nocopybutton"><code>
HOME_THEATER_PACKAGE   COUNT(1)   
                     1       1506 
                     0       1208 

---------------------------</code></pre></div>
</li>
<li class="stepexpand"><span>Build your model using the <code class="codeph">CREATE_MODEL2</code> procedure. First, declare a variable to store model settings or hyperparameters. Run the following script:</span><div>
<pre class="pre codeblock"><code>%script
 
BEGIN DBMS_DATA_MINING.DROP_MODEL('MODEL_RF');
EXCEPTION WHEN OTHERS THEN NULL; END;
/
DECLARE
    v_setlist DBMS_DATA_MINING.SETTING_LIST;
     
BEGIN
    v_setlist('PREP_AUTO') := 'ON';
    v_setlist('ALGO_NAME') := 'ALGO_RANDOM_FOREST';
    v_setlist('RFOR_NUM_TREES') := '25';
     
    DBMS_DATA_MINING.CREATE_MODEL2(
      MODEL_NAME          =&gt;  'MODEL_RF',
      MINING_FUNCTION     =&gt; 'CLASSIFICATION',
      DATA_QUERY          =&gt;  'SELECT * FROM TRAINING_DATA',
      SET_LIST            =&gt;  v_setlist,
      CASE_ID_COLUMN_NAME =&gt;  'CUST_ID',
      TARGET_COLUMN_NAME  =&gt;  'HOME_THEATER_PACKAGE');
END;
 </code></pre>
</div>
<div><pre class="nocopybutton"><code>
PL/SQL procedure successfully completed.

---------------------------
 
PL/SQL procedure successfully completed.</code></pre></div>
<div>
<p>Examine the script:</p>
<ul id="GUID-B2AF509E-03AD-40BE-A7CF-A2109FAC5DE5__UL_FFS_3CX_J4B" style="list-style-type: disc;">
<li><code class="codeph">v_setlist</code> is a variable to store <code class="codeph">SETTING_LIST</code>.
                              </li>
<li><code class="codeph">SETTING_LIST</code> defines model settings or hyperparameters for your model. 
                              </li>
<li><code class="codeph">DBMS_DATA_MINING</code> is the PL/SQL package used for machine learning. These settings are described in <a href="/pls/topic/lookup?ctx=en/database/oracle/machine-learning/oml4sql/23/mlsql&amp;id=ARPLS-GUID-8987EE6F-41A9-4DF9-997C-129B41FDC59A" target="_blank">DBMS_DATA_MINING - Model Settings</a>.
                              </li>
<li><code class="codeph">ALGO_NAME</code> specifies the algorithm name. Since you are using Random Forest as the algorithm, set <code class="codeph">ALGO_RANDOM_FOREST</code>.
                              </li>
<li><code class="codeph">PREP_AUTO</code> is the setting used for Automatic Data Preparation. Here, enable Automatic Data Preparation. The value of the setting is <code class="codeph">ON</code>.
                              </li>
<li><code class="codeph">RFOR_NUM_TREES</code> is the number of trees in the forest. The value here is <code class="codeph">25</code>. Random forest resolves the overfitting problem by training multiple trees on distinct sampled subsets of the data instead of on the same, entire training set. The more trees you select, the more accuracy it can obtain. However, keep in mind that more trees mean more computation load and longer model building time. You need to do a trade-off between the time cost and model accuracy here. Choosing the number of trees equal to 25 allows you to build the model in a reasonably short time and obtain an accurate enough model. 
                              </li>
</ul>
<p>The <code class="codeph">CREATE_MODEL2</code> procedure takes the following parameters:
                           </p>
<ul id="GUID-B2AF509E-03AD-40BE-A7CF-A2109FAC5DE5__UL_GFS_3CX_J4B" style="list-style-type: disc;">
<li>
<p><code class="codeph">MODEL_NAME</code>: A unique model name that you will give to the model. The name of the model is in the form [schema_name.]model_name. If you do not specify a schema, then your own schema is used. Here, the model name is <code class="codeph">MODEL_RF</code></p>
</li>
<li>
<p><code class="codeph">MINING_FUNCTION</code>: Specifies the machine learning function. Since it is a classification problem in this use case, select <code class="codeph">CLASSIFICATION</code>.
                                 </p>
</li>
<li>
<p><code class="codeph">DATA_QUERY</code>: A query that provides training data for building the model. Here, the query is <code class="codeph">SELECT * FROM TRAINING_DATA</code>.
                                 </p>
</li>
<li><code class="codeph">SET_LIST</code>: Specifies <code class="codeph">SETTING_LIST</code>.
                              </li>
<li>
<p><code class="codeph">CASE_ID_COLUMN_NAME</code>: A unique case identifier column in the build data. In this use case, case_id is <code class="codeph">CUST_ID</code>. If there is a composite key, you must create a new attribute before creating the model. The <code class="codeph">CASE_ID</code> assists with reproducible results, joining scores for individual customers with other data in, example, scoring data table.
                                 </p>
</li>
</ul>
<div class="p">
<div class="infoboxnote" id="GUID-B2AF509E-03AD-40BE-A7CF-A2109FAC5DE5__GUID-7D7BD600-DE48-4558-AC5D-A00B82715E04">
<p class="notep1">Note:</p>OML uses either system-determined or default values for any parameters or settings not specified.
                              </div>
</div>
</div>
</li>
</ol>
</div>
</div>