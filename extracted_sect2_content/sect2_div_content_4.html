<div class="sect2"><a id="GUID-CA77A99B-2419-4922-A441-AFB85905C0D0" name="GUID-CA77A99B-2419-4922-A441-AFB85905C0D0"></a><h3 class="sect3" id="MLSQL-GUID-CA77A99B-2419-4922-A441-AFB85905C0D0">Evaluate</h3>
<div>
<p>Evaluate your model by viewing diagnostic metrics and performing quality checks. </p>
<p>Sometimes querying dictionary views and model detail views is sufficient to measure your model's performance. However, you can evaluate your model by computing test metrics such as Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), confusion matrix, lift statistics, cost matrix, and so on. For Association Rules, you can inspect various rules to see if they reveal new insights for item dependencies (antecedent itemset implying consequent) or for unexpected relationships among items.</p>
</div>
<div class="sect3"><a id="GUID-94527B67-D960-4506-942F-FD759589E89D" name="GUID-94527B67-D960-4506-942F-FD759589E89D"></a><h4 class="sect4" id="MLSQL-GUID-94527B67-D960-4506-942F-FD759589E89D">Dictionary and Model Views</h4>
<div>
<p>To obtain information about the model and view model settings, you can query data dictionary views and model detail views. Specific views in model detail views display model statistics which can help you evaluate the model. </p>
<div class="section">
<p>The data dictionary views for Oracle Machine Learning are listed in the following table. A database administrator (DBA) and USER versions of the views are also available.</p>
<div class="tblformal" id="GUID-94527B67-D960-4506-942F-FD759589E89D__d180e253">
<table border="1" cellpadding="4" cellspacing="0" class="Formal" frame="hsides" rules="rows" summary="This table describes the data dictionary views available for machine learning" title="">
<thead>
<tr align="left" valign="top">
<th align="left" id="d30750e827" valign="bottom" width="40%">View Name</th>
<th align="left" id="d30750e829" valign="bottom" width="60%">Description</th>
</tr>
</thead>
<tbody>
<tr align="left" valign="top">
<td align="left" headers="d30750e827" id="d30750e833" valign="top" width="40%"><a href="/pls/topic/lookup?ctx=en/database/oracle/machine-learning/oml4sql/23/mlsql&amp;id=DMAPI-GUID-955402B6-B52E-494A-865B-7BCAFDB124B2" target="_blank">ALL_MINING_MODELS</a></td>
<td align="left" headers="d30750e833 d30750e829" valign="top" width="60%">Provides information about all accessible machine learning models</td>
</tr>
<tr align="left" valign="top">
<td align="left" headers="d30750e827" id="d30750e840" valign="top" width="40%"><a href="/pls/topic/lookup?ctx=en/database/oracle/machine-learning/oml4sql/23/mlsql&amp;id=DMAPI-GUID-E18029D5-09BB-41CB-82BA-894A0528E5EF" target="_blank">ALL_MINING_MODEL_ATTRIBUTES</a></td>
<td align="left" headers="d30750e840 d30750e829" valign="top" width="60%">Provides information about the attributes of all accessible machine learning models</td>
</tr>
<tr align="left" valign="top">
<td align="left" headers="d30750e827" id="d30750e847" valign="top" width="40%"><a href="/pls/topic/lookup?ctx=en/database/oracle/machine-learning/oml4sql/23/mlsql&amp;id=DMAPI-GUID-8262B256-1DFD-40C1-B56C-8E391B5AA303" target="_blank">ALL_MINING_MODEL_SETTINGS</a></td>
<td align="left" headers="d30750e847 d30750e829" valign="top" width="60%">Provides information about the configuration settings for all accessible machine learning models</td>
</tr>
<tr align="left" valign="top">
<td align="left" headers="d30750e827" id="d30750e854" valign="top" width="40%"><a href="/pls/topic/lookup?ctx=en/database/oracle/machine-learning/oml4sql/23/mlsql&amp;id=DMAPI-GUID-69D3A987-CCD8-435A-B624-B3FD0583F02B" target="_blank">ALL_MINING_MODEL_VIEWS</a></td>
<td align="left" headers="d30750e854 d30750e829" valign="top" width="60%">Provides information about the model views for all accessible machine learning models</td>
</tr>
<tr align="left" valign="top">
<td align="left" headers="d30750e827" id="d30750e861" valign="top" width="40%"><a href="/pls/topic/lookup?ctx=en/database/oracle/machine-learning/oml4sql/23/mlsql&amp;id=DMAPI-GUID-40EB4505-47A6-4C1B-85F8-A49BA0906D07" target="_blank">ALL_MINING_MODEL_XFORMS</a></td>
<td align="left" headers="d30750e861 d30750e829" valign="top" width="60%">Provides the user-specified transformations embedded in all accessible machine learning models.</td>
</tr>
</tbody>
</table>
</div>
<p>Model detail views are specific to the algorithm. You can obtain more insights about the model you created by viewing the model detail views. The names of model detail views begin with DM$xx where xx corresponds to the view prefix. See <a href="/pls/topic/lookup?ctx=en/database/oracle/machine-learning/oml4sql/23/mlsql&amp;id=DMPRG-GUID-AF7C531D-5327-4456-854C-9D6424C5F9EC" target="_blank">Model Detail Views</a>.
                        </p>
</div>
<div class="section">
<p>The following steps help you to view different dictionary views and model detail views.</p>
</div>
<ol>
<li class="stepexpand"><span>Run the following statement to view the settings in <code class="codeph">USER_MINING_MODEL_SETTINGS</code>:</span><div><pre class="pre codeblock"><code>%script

SELECT SETTING_NAME, SETTING_VALUE 
  FROM USER_MINING_MODEL_SETTINGS
  WHERE MODEL_NAME='MODEL_RF'
  ORDER BY SETTING_NAME;</code></pre></div>
<div><pre class="nocopybutton"><code>
SETTING_NAME                   SETTING_VALUE             
ALGO_NAME                      ALGO_RANDOM_FOREST        
CLAS_MAX_SUP_BINS              32                        
CLAS_WEIGHTS_BALANCED          OFF                       
ODMS_DETAILS                   ODMS_ENABLE               
ODMS_MISSING_VALUE_TREATMENT   ODMS_MISSING_VALUE_AUTO   
ODMS_RANDOM_SEED               0                         
ODMS_SAMPLING                  ODMS_SAMPLING_DISABLE     
PREP_AUTO                      ON                        
RFOR_NUM_TREES                 25                        
RFOR_SAMPLING_RATIO            .5                        
TREE_IMPURITY_METRIC           TREE_IMPURITY_GINI        
TREE_TERM_MAX_DEPTH            16                        
TREE_TERM_MINPCT_NODE          .05                       
TREE_TERM_MINPCT_SPLIT         .1                        

SETTING_NAME             SETTING_VALUE   
TREE_TERM_MINREC_NODE    10              
TREE_TERM_MINREC_SPLIT   20              


16 rows selected. 
---------------------------</code></pre></div>
</li>
<li class="stepexpand"><span>Run the following statement to see attribute information in <code class="codeph">USER_MINING_MODEL_ATTRIBUTES</code> view:</span><div><pre class="pre codeblock"><code>%script
SELECT ATTRIBUTE_NAME, ATTRIBUTE_TYPE 
FROM USER_MINING_MODEL_ATTRIBUTES 
WHERE MODEL_NAME = 'MODEL_RF' 
ORDER BY ATTRIBUTE_NAME;</code></pre></div>
<div><pre class="nocopybutton"><code>
ATTRIBUTE_NAME         ATTRIBUTE_TYPE   
CUST_CREDIT_LIMIT      NUMERICAL        
HOME_THEATER_PACKAGE   CATEGORICAL      
HOUSEHOLD_SIZE         CATEGORICAL      
OCCUPATION             CATEGORICAL      

---------------------------</code></pre></div>
</li>
<li class="stepexpand"><span>Run the following statement to view various model detail views from <code class="codeph">USER_MINING_MODEL_VIEWS</code>:</span><div><pre class="oac_no_warn" dir="ltr">%script
SELECT VIEW_NAME, VIEW_TYPE
  FROM USER_MINING_MODEL_VIEWS
  WHERE MODEL_NAME='MODEL_RF'
  ORDER BY VIEW_NAME;</pre></div>
<div><pre class="nocopybutton"><code>
VIEW_NAME       VIEW_TYPE                 
DM$VAMODEL_RF   Variable Importance       
DM$VCMODEL_RF   Scoring Cost Matrix       
DM$VGMODEL_RF   Global Name-Value Pairs   
DM$VSMODEL_RF   Computed Settings         
DM$VTMODEL_RF   Classification Targets    
DM$VWMODEL_RF   Model Build Alerts        


6 rows selected. 
---------------------------</code></pre></div>
</li>
<li class="stepexpand"><span>Now, view the Classification targets view. This view describes the target (<code class="codeph">HOME_THEATER_PACKAGE</code>) distribution for classification models.</span><div><pre class="pre codeblock"><code>%script
SELECT* from DM$VTMODEL_RF;</code></pre></div>
<div><pre class="nocopybutton"><code>
PARTITION_NAME   TARGET_VALUE   TARGET_COUNT   TARGET_WEIGHT   
                              0           1178                 
                              1           1549                 

---------------------------</code></pre><p>The distribution value from this view validates the earlier target distribution that was obtained from the training data. The difference in the values is minimal.</p>
</div>
</li>
</ol>
</div>
<div>
<div class="relinfo">
<p><strong>Related Topics</strong></p>
<ul>
<li><a href="/pls/topic/lookup?ctx=en/database/oracle/machine-learning/oml4sql/23/mlsql&amp;id=SQLRF-GUID-25AE84A7-C733-4BC5-8C57-2E5574C49AFC" target="_blank">PREDICTION_SET</a></li>
</ul>
</div>
</div>
</div>
<div class="sect3"><a id="GUID-D7516357-0333-4B6F-8D11-7B042C6FC2D2" name="GUID-D7516357-0333-4B6F-8D11-7B042C6FC2D2"></a><h4 class="sect4" id="MLSQL-GUID-D7516357-0333-4B6F-8D11-7B042C6FC2D2">Test Your Model</h4>
<div>
<p>In this use case, you are evaluating a classification model by computing Lift and Confusion Matrix on the test data with known target values and comparing the predicted values with the known values. </p>
<div class="section">Test metrics are used to assess how accurately the model predicts the known values. If the model performs well and meets your business requirements, it can then be applied to new data to predict the future. These matrices can help you to compare models to arrive at one model that satisfies your evaluation criteria.
                        <p>Lift measures the degree to which the predictions of a classification model are better than randomly-generated predictions. Lift can be understood as a ratio of two percentages: the percentage of correct positive classifications made by the model to the percentage of actual positive classifications in the test data. </p>
<p>A confusion matrix displays the number of correct and incorrect predictions made by the model compared with the actual classifications in the test data. The matrix is n-by-n, where n is the number of classes. </p>
</div>
<ol>
<li class="stepexpand"><span>Create a result table to store the predictions for each row with likely and unlikely probabilities. Run the following script:</span><div><pre class="oac_no_warn" dir="ltr">%script
 
BEGIN EXECUTE IMMEDIATE 'DROP TABLE APPLY_RESULT PURGE';
EXCEPTION WHEN OTHERS THEN NULL; END;
/
 
CREATE TABLE APPLY_RESULT AS
    SELECT cust_id, t.prediction, t.probability
    FROM TEST_DATA, TABLE(PREDICTION_SET(MODEL_RF USING *)) t;
 </pre></div>
<div><pre class="nocopybutton"><code>
PL/SQL procedure successfully completed.
---------------------------
Table APPLY_RESULT created.
---------------------------</code></pre><p>Examine the script:</p>
<p><code class="codeph">APPLY_RESULT</code>: is a table that stores the results of the prediction.
                              </p>
<p><code class="codeph">TABLE(PREDICTION_SET(MODEL_RF USING *))</code>: is a table that has results from the <code class="codeph">PREDICTION_SET</code> query. The <code class="codeph">PREDICTION_SET</code> query returns probabilities for each row.
                              </p>
</div>
</li>
<li class="stepexpand"><span>Compute lift by using the <code class="codeph">DBMS_DATA_MINING.APPLY</code> and the <code class="codeph">DBMS_DATA_MINING.COMPUTE_LIFT</code> procedures:</span><div><pre class="oac_no_warn" dir="ltr">%script
 
BEGIN EXECUTE IMMEDIATE 'DROP TABLE APPLY_RESULT PURGE';
EXCEPTION WHEN OTHERS THEN NULL; END;
/
 
BEGIN
  DBMS_DATA_MINING.APPLY('MODEL_RF','TEST_DATA','CUST_ID','APPLY_RESULT');
   
                                  
     
       DBMS_DATA_MINING.COMPUTE_LIFT (
          apply_result_table_name           =&gt; 'APPLY_RESULT',
          target_table_name                  =&gt; 'TEST_DATA',
          case_id_column_name               =&gt; 'CUST_ID',
          target_column_name                 =&gt; 'HOME_THEATER_PACKAGE',
          lift_table_name                       =&gt; 'LIFT_TABLE',
          positive_target_value           =&gt;  to_char(1),
          score_column_name                  =&gt; 'PREDICTION',
          score_criterion_column_name    =&gt; 'PROBABILITY',
          num_quantiles                       =&gt;  10,
          cost_matrix_table_name             =&gt;  null,
          apply_result_schema_name         =&gt;  null,
          target_schema_name                 =&gt;  null,
          cost_matrix_schema_name           =&gt;  null,
          score_criterion_type             =&gt;  'PROBABILITY');
     
                                  
END;
 </pre></div>
<div><pre class="nocopybutton"><code>
PL/SQL procedure successfully completed.
---------------------------
PL/SQL procedure successfully completed.</code></pre><p>Examine the script:</p>
<ul id="GUID-D7516357-0333-4B6F-8D11-7B042C6FC2D2__UL_Y3W_K24_N4B" style="list-style-type: disc;">
<li><code class="codeph">DBMS_DATA_MINING.APPLY</code>: This procedure creates a table in the user's schema to hold the results. The <code class="codeph">APPLY</code> procedure generates predictions (scores) in a target column.
                                    <p>The <code class="codeph">APPLY</code> procedure has the following parameters:
                                    </p>
<ul id="GUID-D7516357-0333-4B6F-8D11-7B042C6FC2D2__UL_NW2_GGG_PPB" style="list-style-type: disc;">
<li><code class="codeph">model_name</code>: Name of the model in the form [schema_name.]model_name. If you do not specify a schema, then your own schema is used. Here, the model name is <code class="codeph">MODEL_RF</code>.
                                       </li>
<li><code class="codeph">data_table_name</code>: Name of table or view containing the data to be scored. Here, you are using <code class="codeph">TEST_DATA</code>.
                                       </li>
<li><code class="codeph">case_id_column_name</code>: Name of the case identifier column. The case ID is <code class="codeph">CUST_ID</code>.
                                       </li>
<li><code class="codeph">result_table_name</code>: Name of the table in which to store apply results. Here, the result table name is <code class="codeph">APPLY_RESULT</code>.
                                       </li>
</ul>
</li>
<li><code class="codeph">DBMS_DATA_MINING.COMPUTE_LIFT</code>: This procedure computes lift and stores them in the user's schema. To compute lift, one of the target values must be designated as the positive class.
                                    <div class="p">The <code class="codeph">COMPUTE_LIFT</code> procedure has the following parameters:
                                       <ul id="GUID-D7516357-0333-4B6F-8D11-7B042C6FC2D2__UL_TJG_Y3G_PPB" style="list-style-type: disc;">
<li><code class="codeph">apply_result_table_name</code>: Table containing the predictions. For this use case, it is <code class="codeph">APPLY_RESULT</code>.
                                          </li>
<li><code class="codeph">target_table_name</code>: Table containing the known target values from the test data. In this use case, the target table name is <code class="codeph">TEST_DATA</code>. 
                                          </li>
<li><code class="codeph">case_id_column_name</code>: Case ID column in the apply results table. Must match the case identifier in the targets table. The case ID column is <code class="codeph">CUST_ID</code>.
                                          </li>
<li><code class="codeph">target_column_name</code>: Target column in the targets table. Contains the known target values from the test data. In this use case, the target is <code class="codeph">HOME_THEATER_PACKAGE</code>.
                                          </li>
<li><code class="codeph">lift_table_name</code>: Table containing the lift statistics. The table will be created by the procedure in the user's schema. Type <code class="codeph">LIFT_TABLE</code>.
                                          </li>
<li><code class="codeph">positive_target_value</code>: The positive class. This should be the class of interest, for which you want to calculate lift. If the target column is a <code class="codeph">NUMBER</code>, you can use the <code class="codeph">TO_CHAR()</code> operator to provide the value as a string. 
                                          </li>
<li><code class="codeph">score_column_name</code>: Column containing the predictions in the apply results table. The default column name is <code class="codeph">'PREDICTION'</code>, which is the default name created by the <code class="codeph">APPLY</code> procedure. 
                                          </li>
<li><code class="codeph">score_criterion_column_name</code>: Column containing the scoring criterion in the apply results table. Contains either the probabilities or the costs that determine the predictions. By default, scoring is based on probability; the class with the highest probability is predicted for each case. If scoring is based on cost, the class with the lowest cost is predicted. The <code class="codeph">score_criterion_type</code> parameter indicates whether probabilities or costs will be used for scoring. The default column name is <code class="codeph">'PROBABILITY'</code>, which is the default name created by the <code class="codeph">APPLY</code> procedure. 
                                          </li>
<li><code class="codeph">num_quantiles</code>: Number of quantiles to be used in calculating lift. The default is 10. 
                                          </li>
<li><code class="codeph">cost_matrix_table_name</code>: (Optional) Table that defines the costs associated with misclassifications. If a cost matrix table is provided and the score_criterion_type parameter is set to <code class="codeph">'COST'</code>, the costs will be used as the scoring criteria. 
                                          </li>
<li><code class="codeph">apply_result_schema_name</code>: Schema of the apply results table. If null, the user's schema is assumed. 
                                          </li>
<li><code class="codeph">target_schema_name</code>: Schema of the table containing the known targets. If null, the user's schema is assumed. 
                                          </li>
<li><code class="codeph">cost_matrix_schema_name</code>: Schema of the cost matrix table, if one is provided. If null, the user's schema is assumed. 
                                          </li>
<li><code class="codeph">score_criterion_type</code>: Whether to use probabilities or costs as the scoring criterion. Probabilities or costs are passed in the column identified in the score_criterion_column_name parameter. The default value of <code class="codeph">score_criterion_type</code> is <code class="codeph">'PROBABILITY'</code>. To use costs as the scoring criterion, specify <code class="codeph">'COST'</code>. If <code class="codeph">score_criterion_type</code> is set to <code class="codeph">'COST'</code> but no cost matrix is provided and if there is a scoring cost matrix associated with the model, then the associated costs are used for scoring. 
                                          </li>
</ul>
</div>
</li>
</ul>
</div>
</li>
<li class="stepexpand"><span>To view the cumulative gains, run the following statement: </span><div>
<p>Cumulative gain is the ratio of the cumulative number of positive targets (<code class="codeph">HOME_THEATER_PACKAGE</code>) to the total number of positive targets of a quantile. Cumulative gains act as a visual aid for measuring performance of a model. The chart consists of a curve and a baseline. The greater the area between the curve and the baseline, the better the model.
                              </p>
</div>
<div><pre class="oac_no_warn" dir="ltr">%sql
SELECT QUANTILE_NUMBER, GAIN_CUMULATIVE FROM LIFT_TABLE;</pre></div>
<div><img alt="Cumulative gains with positive HOME_THEATER_PACKAGE respondents" height="610" id="GUID-D7516357-0333-4B6F-8D11-7B042C6FC2D2__IMAGE_DCP_4RB_Q4B" src="img/classification_cumulative_gains.png" title="Cumulative gains with positive HOME_THEATER_PACKAGE respondents" width="703"/><img alt="Cumulative gains for each quantile." height="616" id="GUID-D7516357-0333-4B6F-8D11-7B042C6FC2D2__IMAGE_B12_GFP_NPB" src="img/classification_cumulative_gains_chart.png" title="Cumulative gains for each quantile." width="717"/></div>
</li>
<li class="stepexpand"><span>To compute confusion matrix, run the following statement:</span><div>A confusion matrix evaluates the prediction results. It makes it easy to understand and estimate the effects of wrong predictions. You can observe the number and percentages in each cell of this matrix and notice how often the model predicted accurately.</div>
<div><pre class="pre codeblock"><code>%script

DECLARE
   v_accuracy NUMBER;       
   BEGIN
        DBMS_DATA_MINING.COMPUTE_CONFUSION_MATRIX (
                   accuracy =&gt; v_accuracy,
                   apply_result_table_name =&gt; 'apply_result',
                   target_table_name =&gt; 'test_data',
                   case_id_column_name =&gt; 'cust_id',
                   target_column_name =&gt; 'HOME_THEATER_PACKAGE',
                   confusion_matrix_table_name =&gt; 'confusion_matrix',
                   score_column_name =&gt; 'PREDICTION',
                   score_criterion_column_name =&gt; 'PROBABILITY',
                   cost_matrix_table_name =&gt; null,
                   apply_result_schema_name =&gt; null,
                   target_schema_name =&gt; null,
                   cost_matrix_schema_name =&gt; null,
                   score_criterion_type =&gt; 'PROBABILITY');
        DBMS_OUTPUT.PUT_LINE('**** MODEL ACCURACY ****: ' || ROUND(v_accuracy,4));
      END;
      /</code></pre></div>
<div><pre class="nocopybutton"><code>**** MODEL ACCURACY ****: .696
---------------------------
PL/SQL procedure successfully completed.
---------------------------
</code></pre><p>Examine the script:</p>
<p><code class="codeph">v_accuracy</code> is a variable declared for this procedure to store and output the model accuracy percentage.
                              </p>
<p>The <code class="codeph">COMPUTE_CONFUSION_MATRIX</code> procedure has the following parameters:
                              </p>
<ul id="GUID-D7516357-0333-4B6F-8D11-7B042C6FC2D2__UL_EGY_FSG_PPB" style="list-style-type: disc;">
<li><code class="codeph">accuracy</code>: Output parameter containing the overall percentage accuracy of the predictions. Here, it is <code class="codeph">v_accuracy</code>.
                                 </li>
<li><code class="codeph">apply_result_table_name</code>: Table containing the predictions. In this use case, it is <code class="codeph">APPLY_RESULT</code>.
                                 </li>
<li><code class="codeph">target_table_name</code>: Table containing the known target values from the test data. In this use case, you are using <code class="codeph">TEST_DATA</code>.
                                 </li>
<li><code class="codeph">case_id_column_name</code>: Case ID column in the apply results table. Must match the case identifier in the targets table. Here, it is <code class="codeph">CUST_ID</code>.
                                 </li>
<li><code class="codeph">target_column_name</code>: Target column in the targets table. Contains the known target values from the test data. In this use case, the target column is <code class="codeph">HOME_THEATER_PACKAGE</code>.
                                 </li>
<li><code class="codeph">confusion_matrix_table_name</code>: Table containing the confusion matrix. The table will be created by the procedure in the user's schema. Here set it as <code class="codeph">confusion_matrix</code>.
                                 </li>
<li><code class="codeph">score_column_name</code>: Column containing the predictions in the apply results table. The default column name is <code class="codeph">PREDICTION</code>, which is the default name created by the <code class="codeph">APPLY</code> procedure. 
                                 </li>
<li><code class="codeph">score_criterion_column_name</code>: Column containing the scoring criterion in the apply results table. Contains either the probabilities or the costs that determine the predictions. By default, scoring is based on probability; the class with the highest probability is predicted for each case. If scoring is based on cost, the class with the lowest cost is predicted. The <code class="codeph">score_criterion_type</code> parameter indicates whether probabilities or costs will be used for scoring. The default column name is <code class="codeph">'PROBABILITY'</code>, which is the default name created by the <code class="codeph">APPLY</code> procedure. 
                                 </li>
<li><code class="codeph">cost_matrix_table_name</code>: (Optional) Table that defines the costs associated with misclassifications. If a cost matrix table is provided and the <code class="codeph">score_criterion_type</code> parameter is set to <code class="codeph">'COSTS'</code>, the costs in this table will be used as the scoring criteria. Otherwise, set it as <code class="codeph">null</code>.
                                 </li>
<li><code class="codeph">apply_result_schema_name</code>: Schema of the apply results table. If null, the user's schema is assumed.
                                 </li>
<li><code class="codeph">target_schema_name</code>: Schema of the table containing the known targets. If null, the user's schema is assumed.
                                 </li>
<li><code class="codeph">cost_matrix_schema_name</code>: Schema of the cost matrix table, if one is provided. If null, the user's schema is assumed.
                                 </li>
<li><code class="codeph">score_criterion_type</code>: Whether to use probabilities or costs as the scoring criterion. Probabilities or costs are passed in the column identified in the<code class="codeph"> score_criterion_column_name</code> parameter. The default value of <code class="codeph">score_criterion_type</code> is <code class="codeph">'PROBABILITY'</code>. To use costs as the scoring criterion, specify <code class="codeph">'COST'</code>. If <code class="codeph">score_criterion_type</code> is set to <code class="codeph">'COST'</code> but no cost matrix is provided and if there is a scoring cost matrix associated with the model, then the associated costs are used for scoring. 
                                 </li>
</ul>
<p><code class="codeph">DBMS_OUTPUT.PUT_LINE('**** MODEL ACCURACY ****: ' || ROUND(v_accuracy,4))</code>: Outputs the model accuracy percentage rounded to 4 digits after the decimal.
                              </p>
</div>
</li>
<li class="stepexpand"><span>To check the confusion matrix with predicted values and actual values, run the following statement:</span><div><pre class="pre codeblock"><code>select * from confusion_matrix;</code></pre></div>
<div><pre class="nocopybutton"><code>
ACTUAL_TARGET_VALUE   PREDICTED_TARGET_VALUE   VALUE   
                    0                        1     501 
                    0                        0     282 
                    1                        0      38 
                    1                        1     952 

---------------------------</code></pre><p>The value column here indicates classification. From this confusion matrix, the model has predicted actual positive class (also called as True Positive (TP)) for this use case 952 times and incorrectly predicted (also called as False Negative (FN)) for this use case 38 times. The model correctly predicted the negative class (also called true negative (TN)) for this use case 282 times and incorrectly predicted (also called false positive (FP)) for this use case 501 times. </p>
</div>
</li>
</ol>
<div class="section">The accuracy percentage of 69% shows that the model is fairly good for this use case.</div>
</div>
<div>
<div class="relinfo">
<p><strong>Related Topics</strong></p>
<ul>
<li><a href="/pls/topic/lookup?ctx=en/database/oracle/machine-learning/oml4sql/23/mlsql&amp;id=SQLRF-GUID-25AE84A7-C733-4BC5-8C57-2E5574C49AFC" target="_blank">PREDICTION_SET</a></li>
</ul>
</div>
</div>
</div>
</div>